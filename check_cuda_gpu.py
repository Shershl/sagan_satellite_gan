import torch
import time

print("üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ CUDA:")

if torch.cuda.is_available():
    print("‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞")
    print("üñ•Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è GPU:", torch.cuda.get_device_name(0))
    print("üöÄ –í–∏–∫–æ–Ω—É—î–º–æ —Ç–µ—Å—Ç–æ–≤–µ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –Ω–∞ GPU...")

    device = torch.device("cuda")

    a = torch.randn((10000, 10000), device=device)
    b = torch.randn((10000, 10000), device=device)

    start = time.time()
    c = torch.matmul(a, b)
    torch.cuda.synchronize()
    end = time.time()

    print(f"‚úÖ –û–±—á–∏—Å–ª–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –Ω–∞ GPU –∑–∞ {end - start:.3f} —Å")

else:
    print("‚ùå CUDA –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ ‚Äî —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –π–¥–µ –Ω–∞ CPU")
